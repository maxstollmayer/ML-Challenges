{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7bba1a-0684-4e0f-be87-f0578911fd47",
   "metadata": {},
   "source": [
    "\n",
    "<h1>petersen2smiley</h1>\n",
    "\n",
    "<br/><br/>\n",
    "    \n",
    "Since we reached 100% on the test set, we wanted to come up with a creative idea. The plan was as follows:\n",
    "\n",
    "\n",
    "1. Extract faces of Prof. Petersen from the frames of the recordings of lectures with the FaceNet \n",
    "   network (https://github.com/timesler/facenet-pytorch).\n",
    "2. Convert the numpy array into a format we can train our CycleGAN in the next step which are \n",
    "   jpg images in RGB.\n",
    "3. Train a petersen2smiley CycleGAN (https://github.com/LynnHo/CycleGAN-Tensorflow-2) between Prof. Petersen \n",
    "   and the Facial Expressions.\n",
    "4. After doing the inference we still have the annotated data - now having a face of Prof. Petersen \n",
    "   corresponding to a facial expression. \n",
    "5. We would now use the Autokeras (https://autokeras.com/) library to train the classifier in the usual way.\n",
    "\n",
    "CycleGAN doesn't need a correspondence between the source and target domain, which very good fits into\n",
    "our idea. The idea of CycleGAN is to learn a mapping G: X -> Y where the distribution of images betwen Y and \n",
    "G(X) is indistinguishable. \n",
    "\n",
    "Problems that arose with this type of generative adversarial network is the very long training time to even\n",
    "get reasonable results (we trained on one middle class GPU). \n",
    "\n",
    "We thus just present some of the more interesting results of the CycleGAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22450ec5-1349-42b4-b0e9-5edfa70c8535",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c14830-b558-4f23-9608-3e0dec85f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "smileys = np.load(\"data_train_Facial.npy\", allow_pickle = True)\n",
    "labels = np.loadtxt(\"true_labels_Facial_train.csv\", delimiter = \",\")\n",
    "smiley_count = smileys.shape[0]\n",
    "image_size = smileys.shape[1]\n",
    "\n",
    "video = cv2.VideoCapture(\"lectures.mp4\")\n",
    "video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511850c0-c7f2-415f-9b50-540c7d9c8d8e",
   "metadata": {},
   "source": [
    "### Extract Faces from Lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fba03e9-372a-4777-a8c3-31c850f7a0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccfe47fa3d74d618bd5a68e8f141741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create face detector\n",
    "mtcnn = MTCNN(image_size = image_size, select_largest = False, post_process = False)\n",
    "\n",
    "# loop through video frames\n",
    "for frame_number in tqdm(range(video_length)):\n",
    "    \n",
    "    # load frame\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        continue\n",
    "        \n",
    "    # convert to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # save face\n",
    "    mtcnn(frame, save_path = f\"CycleGAN\\\\datasets\\\\petersen2smiley\\\\trainB\\\\face_{frame_number:05d}.jpg\")\n",
    "\n",
    "# save last face to test folder\n",
    "mtcnn(frame, save_path = \"CycleGAN\\\\datasets\\\\petersen2smiley\\\\trainB\\\\face_test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bffef8-8ee3-4ad2-96ab-bfd5f02f94cf",
   "metadata": {},
   "source": [
    "### Save Smileys as PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f101c493-b124-45b3-b2b8-a642760a8dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0d7644ddcd477a82109e016c31d0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(smiley_count)):\n",
    "    \n",
    "    smiley = np.uint8(smileys[index])\n",
    "    \n",
    "    # create empty image\n",
    "    image = Image.new(mode = \"RGB\", size = smiley.shape)\n",
    "    pixels = image.load()\n",
    "    \n",
    "    # loop through pixels\n",
    "    for i in range(image.size[0]):\n",
    "        for j in range(image.size[1]):\n",
    "            \n",
    "            # set pixel to white\n",
    "            if smiley[i,j] == 0:\n",
    "                pixels[j,i] = (255, 255, 255)\n",
    "                \n",
    "            # set pixel to yellow\n",
    "            elif smiley[i,j] == 1:\n",
    "                pixels[j,i] = (255, 255, 0)\n",
    "                \n",
    "            # else pixels are black\n",
    "        \n",
    "    # save smiley image\n",
    "    image.save(f\"CycleGAN\\\\datasets\\\\petersen2smiley\\\\trainA\\\\smiley_{index:05d}.jpg\")\n",
    "\n",
    "# save last smiley to test folder\n",
    "image.save(\"CycleGAN\\\\datasets\\\\petersen2smiley\\\\testA\\\\smiley_test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e04cd5-d2dd-4045-a19b-0a113e3b6a7b",
   "metadata": {},
   "source": [
    "### Train CycleGAN\n",
    "\n",
    "zip the whole folder and train cyclegan with these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca54578-e2f6-48bb-b51c-e596cf86069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train.py --dataset petersen2smiley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7cada-43ae-4f48-bc9c-e37e2e48e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(\"./examples/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafb169-20b0-4c77-87aa-c35d84d68eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0b4dc-ef77-46b3-90d0-142ed83cca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d316c7-4b13-4c6f-9877-733262ffb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14d7f3-3925-49d5-8a2d-95d6e7d2d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b0388-885a-432a-b81a-6e95a4e339c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea15d9-72a6-4445-a405-a863e004fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e29564-051f-4fcf-bfad-71c020855cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"./examples/8.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0c4fb-841a-4ce7-9815-0bfc4aec9ace",
   "metadata": {},
   "source": [
    "### Use Expression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225abc1-c82d-441f-9488-3063bb570a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24860da6-1b7d-4958-b9a7-d38bd5ff6f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd6563-0a88-404d-9b24-d3731f52b4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cf2ce-1332-4121-883d-79ab18d946e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
